{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: Data.DataLoader\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Flux: @epochs\n",
    "using Statistics\n",
    "using MLDatasets\n",
    "using Serialization: serialize, deserialize\n",
    "using PyCall\n",
    "using ImageView\n",
    "using Flux\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FixedPointNumbers.N0f8[0.149N0f8 0.153N0f8 … 0.196N0f8 0.188N0f8; 0.153N0f8 0.153N0f8 … 0.2N0f8 0.188N0f8; … ; 0.165N0f8 0.169N0f8 … 0.176N0f8 0.173N0f8; 0.153N0f8 0.153N0f8 … 0.165N0f8 0.165N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.404N0f8 0.408N0f8 … 0.459N0f8 0.451N0f8; 0.408N0f8 0.408N0f8 … 0.463N0f8 0.451N0f8; … ; 0.404N0f8 0.396N0f8 … 0.455N0f8 0.451N0f8; 0.38N0f8 0.38N0f8 … 0.443N0f8 0.443N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.235N0f8 0.239N0f8 … 0.298N0f8 0.29N0f8; 0.239N0f8 0.239N0f8 … 0.302N0f8 0.29N0f8; … ; 0.243N0f8 0.247N0f8 … 0.282N0f8 0.278N0f8; 0.224N0f8 0.224N0f8 … 0.271N0f8 0.278N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.506N0f8 0.525N0f8 … 0.541N0f8 0.514N0f8; 0.498N0f8 0.522N0f8 … 0.51N0f8 0.478N0f8; … ; 0.482N0f8 0.494N0f8 … 0.396N0f8 0.435N0f8; 0.482N0f8 0.49N0f8 … 0.439N0f8 0.482N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.557N0f8 0.588N0f8 … 0.596N0f8 0.569N0f8; 0.561N0f8 0.584N0f8 … 0.565N0f8 0.533N0f8; … ; 0.525N0f8 0.537N0f8 … 0.42N0f8 0.463N0f8; 0.529N0f8 0.537N0f8 … 0.463N0f8 0.51N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.6N0f8 0.627N0f8 … 0.647N0f8 0.62N0f8; 0.596N0f8 0.62N0f8 … 0.616N0f8 0.584N0f8; … ; 0.612N0f8 0.616N0f8 … 0.525N0f8 0.565N0f8; 0.616N0f8 0.62N0f8 … 0.565N0f8 0.612N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.588N0f8 0.588N0f8 … 0.576N0f8 0.624N0f8; 0.588N0f8 0.592N0f8 … 0.576N0f8 0.624N0f8; … ; 0.588N0f8 0.6N0f8 … 0.545N0f8 0.596N0f8; 0.576N0f8 0.588N0f8 … 0.541N0f8 0.596N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.627N0f8 0.627N0f8 … 0.647N0f8 0.694N0f8; 0.639N0f8 0.639N0f8 … 0.643N0f8 0.694N0f8; … ; 0.671N0f8 0.671N0f8 … 0.608N0f8 0.659N0f8; 0.663N0f8 0.663N0f8 … 0.608N0f8 0.659N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.663N0f8 0.663N0f8 … 0.702N0f8 0.741N0f8; 0.667N0f8 0.663N0f8 … 0.702N0f8 0.745N0f8; … ; 0.71N0f8 0.706N0f8 … 0.667N0f8 0.714N0f8; 0.706N0f8 0.702N0f8 … 0.671N0f8 0.718N0f8]\n",
       "\n",
       "...\n",
       "\n",
       "FixedPointNumbers.N0f8[0.451N0f8 0.478N0f8 … 0.459N0f8 0.518N0f8; 0.455N0f8 0.482N0f8 … 0.459N0f8 0.522N0f8; … ; 0.447N0f8 0.463N0f8 … 0.561N0f8 0.561N0f8; 0.451N0f8 0.467N0f8 … 0.565N0f8 0.565N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.518N0f8 0.545N0f8 … 0.478N0f8 0.541N0f8; 0.522N0f8 0.549N0f8 … 0.478N0f8 0.549N0f8; … ; 0.533N0f8 0.545N0f8 … 0.612N0f8 0.612N0f8; 0.533N0f8 0.545N0f8 … 0.616N0f8 0.616N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.557N0f8 0.58N0f8 … 0.537N0f8 0.596N0f8; 0.561N0f8 0.584N0f8 … 0.537N0f8 0.596N0f8; … ; 0.557N0f8 0.569N0f8 … 0.643N0f8 0.647N0f8; 0.561N0f8 0.573N0f8 … 0.647N0f8 0.647N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.376N0f8 0.376N0f8 … 0.384N0f8 0.38N0f8; 0.38N0f8 0.38N0f8 … 0.388N0f8 0.388N0f8; … ; 0.341N0f8 0.341N0f8 … 0.463N0f8 0.435N0f8; 0.345N0f8 0.345N0f8 … 0.431N0f8 0.408N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.255N0f8 0.255N0f8 … 0.263N0f8 0.259N0f8; 0.255N0f8 0.255N0f8 … 0.275N0f8 0.271N0f8; … ; 0.243N0f8 0.247N0f8 … 0.388N0f8 0.361N0f8; 0.247N0f8 0.251N0f8 … 0.357N0f8 0.333N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.184N0f8 0.188N0f8 … 0.18N0f8 0.176N0f8; 0.192N0f8 0.196N0f8 … 0.188N0f8 0.188N0f8; … ; 0.216N0f8 0.212N0f8 … 0.325N0f8 0.29N0f8; 0.22N0f8 0.216N0f8 … 0.294N0f8 0.267N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.396N0f8 0.427N0f8 … 0.408N0f8 0.373N0f8; 0.392N0f8 0.42N0f8 … 0.412N0f8 0.376N0f8; … ; 0.373N0f8 0.365N0f8 … 0.4N0f8 0.4N0f8; 0.376N0f8 0.365N0f8 … 0.4N0f8 0.4N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.294N0f8 0.329N0f8 … 0.325N0f8 0.286N0f8; 0.286N0f8 0.314N0f8 … 0.329N0f8 0.29N0f8; … ; 0.247N0f8 0.239N0f8 … 0.278N0f8 0.278N0f8; 0.251N0f8 0.239N0f8 … 0.278N0f8 0.278N0f8]\n",
       "\n",
       "FixedPointNumbers.N0f8[0.235N0f8 0.271N0f8 … 0.278N0f8 0.243N0f8; 0.235N0f8 0.263N0f8 … 0.286N0f8 0.247N0f8; … ; 0.204N0f8 0.196N0f8 … 0.196N0f8 0.196N0f8; 0.2N0f8 0.192N0f8 … 0.196N0f8 0.196N0f8], [5, 2, 1, 10, 6, 1, 9, 1, 1, 8  …  1, 7, 1, 3, 6, 2, 2, 7, 6, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = SVHN2.traindata()\n",
    "x_test, y_test = SVHN2.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100;\n",
    "batch_size = 64;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_minibatch (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X[:,:,1, 1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] .= Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 1:10)\n",
    "    return (X_batch, Y_batch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_idxs = partition(1:length(x_train[:,:,:,1]), batch_size)\n",
    "train_set = [make_minibatch(x_train, y_train, i) for i in mb_idxs];\n",
    "mb_idxs_test = partition(1:length(x_test[:,:,:,1]), batch_size)\n",
    "x_test = x_test[:,:,:,3072] #zmniejszam próbe testową bo mam za mało pamięci\n",
    "test_set = make_minibatch(x_test, y_test, 1:length(x_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.001, (0.9, 0.999), IdDict{Any, Any}())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(x, y)\n",
    "    x_aug = x .+ 0.1f0*randn(eltype(x), size(x)) #szum losowy\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "opt = ADAM(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    #Dense(32, 10, relu),\n",
    "    softmax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 10 and 32\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 10 and 32\")",
      "",
      "Stacktrace:",
      "  [1] _bcs1",
      "    @ .\\broadcast.jl:501 [inlined]",
      "  [2] _bcs(shape::Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, newshape::NTuple{4, Base.OneTo{Int64}})",
      "    @ Base.Broadcast .\\broadcast.jl:495",
      "  [3] broadcast_shape",
      "    @ .\\broadcast.jl:489 [inlined]",
      "  [4] combine_axes",
      "    @ .\\broadcast.jl:484 [inlined]",
      "  [5] instantiate",
      "    @ .\\broadcast.jl:266 [inlined]",
      "  [6] materialize",
      "    @ .\\broadcast.jl:883 [inlined]",
      "  [7] adjoint",
      "    @ ~\\.julia\\packages\\Flux\\0c9kI\\src\\losses\\utils.jl:22 [inlined]",
      "  [8] _pullback",
      "    @ ~\\.julia\\packages\\ZygoteRules\\OjfTt\\src\\adjoint.jl:57 [inlined]",
      "  [9] _pullback",
      "    @ ~\\.julia\\packages\\Flux\\0c9kI\\src\\losses\\functions.jl:206 [inlined]",
      " [10] _pullback(::Zygote.Context, ::Flux.Losses.var\"##crossentropy#10\", ::Int64, ::typeof(mean), ::Float32, ::typeof(crossentropy), ::Array{Float32, 4}, ::Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}})",
      "    @ Zygote ~\\.julia\\packages\\Zygote\\zowrf\\src\\compiler\\interface2.jl:0",
      " [11] _pullback",
      "    @ ~\\.julia\\packages\\Flux\\0c9kI\\src\\losses\\functions.jl:206 [inlined]",
      " [12] _pullback(::Zygote.Context, ::typeof(crossentropy), ::Array{Float32, 4}, ::Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}})",
      "    @ Zygote ~\\.julia\\packages\\Zygote\\zowrf\\src\\compiler\\interface2.jl:0",
      " [13] _pullback",
      "    @ .\\In[20]:4 [inlined]",
      " [14] _pullback(::Zygote.Context, ::typeof(loss), ::Array{Float32, 4}, ::Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}})",
      "    @ Zygote ~\\.julia\\packages\\Zygote\\zowrf\\src\\compiler\\interface2.jl:0",
      " [15] _apply",
      "    @ .\\boot.jl:804 [inlined]",
      " [16] adjoint",
      "    @ ~\\.julia\\packages\\Zygote\\zowrf\\src\\lib\\lib.jl:191 [inlined]",
      " [17] _pullback",
      "    @ ~\\.julia\\packages\\ZygoteRules\\OjfTt\\src\\adjoint.jl:57 [inlined]",
      " [18] _pullback",
      "    @ ~\\.julia\\packages\\Flux\\0c9kI\\src\\optimise\\train.jl:102 [inlined]",
      " [19] _pullback(::Zygote.Context, ::Flux.Optimise.var\"#39#45\"{typeof(loss), Tuple{Array{Float32, 4}, Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}}}})",
      "    @ Zygote ~\\.julia\\packages\\Zygote\\zowrf\\src\\compiler\\interface2.jl:0",
      " [20] pullback(f::Function, ps::Zygote.Params)",
      "    @ Zygote ~\\.julia\\packages\\Zygote\\zowrf\\src\\compiler\\interface.jl:250",
      " [21] gradient(f::Function, args::Zygote.Params)",
      "    @ Zygote ~\\.julia\\packages\\Zygote\\zowrf\\src\\compiler\\interface.jl:58",
      " [22] macro expansion",
      "    @ ~\\.julia\\packages\\Flux\\0c9kI\\src\\optimise\\train.jl:101 [inlined]",
      " [23] macro expansion",
      "    @ ~\\.julia\\packages\\Juno\\n6wyj\\src\\progress.jl:134 [inlined]",
      " [24] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{Array{Float32, 4}, Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}}}}, opt::ADAM; cb::Flux.Optimise.var\"#40#46\")",
      "    @ Flux.Optimise ~\\.julia\\packages\\Flux\\0c9kI\\src\\optimise\\train.jl:99",
      " [25] train!(loss::Function, ps::Zygote.Params, data::Vector{Tuple{Array{Float32, 4}, Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}}}}, opt::ADAM)",
      "    @ Flux.Optimise ~\\.julia\\packages\\Flux\\0c9kI\\src\\optimise\\train.jl:97",
      " [26] top-level scope",
      "    @ In[52]:1",
      " [27] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [28] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, params(model), train_set, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
