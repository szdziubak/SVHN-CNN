{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: Data.DataLoader\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Flux: @epochs\n",
    "using Statistics\n",
    "using MLDatasets: SVHN2\n",
    "using Serialization: serialize, deserialize\n",
    "using PyCall\n",
    "using ImageView\n",
    "using Images\n",
    "using Flux\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON, LinearAlgebra\n",
    "using Metalhead: trainimgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = SVHN2.traindata()\n",
    "x_test, y_test = SVHN2.testdata();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40;\n",
    "batch_size = 256;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_imgs = [Float32.(x_train[:, :, :, i]) for i in 1:size(x_train)[4]]\n",
    "train_labels = onehotbatch(reshape(y_train, (1, size(y_train)[1])), 1:10)\n",
    "train_X = [(cat(train_imgs[i]..., dims = 4), train_labels[:, i]) for i in partition(1:size(x_train)[4], batch_size)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [Float32.(x_test[:, :, :, i]) for i in 1:5000]\n",
    "test_labels = onehotbatch(y_test[1:5000], 1:10)\n",
    "test_X = cat(test_imgs..., dims = 4)\n",
    "test_Y = [test_labels[:, i] for i in 1:5000];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 3=>8, pad=(1, 1), stride=(1, 1), relu),\n",
    "    BatchNorm(8),\n",
    "    Conv((3, 3), 8=>16, pad=(2, 2), stride=(1, 1), relu),\n",
    "    BatchNorm(16),\n",
    "    Conv((3, 3), 16=>32, pad=(2, 2), stride=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    Conv((3, 3), 32=>32, pad=(2, 2), stride=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    MeanPool((4, 4)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(2592, 10),\n",
    "    softmax\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.01, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(model(x), y)\n",
    "accuracy(x, y) = mean(onecold(model(x), 1:10) .== onecold(y, 1:10))\n",
    "opt = ADAM(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×256 Array{Float32,2}:\n",
       " 0.0988194  0.0981398  0.0888327  …  0.096061   0.0972657  0.0962161\n",
       " 0.101817   0.102203   0.109146      0.103691   0.103138   0.104832\n",
       " 0.0992016  0.0989206  0.0951156     0.102918   0.0998823  0.10047\n",
       " 0.100163   0.100727   0.101675      0.100443   0.0999007  0.100268\n",
       " 0.0967751  0.0971531  0.0921852     0.0952351  0.0948097  0.0930415\n",
       " 0.106066   0.105549   0.115818   …  0.105615   0.106276   0.106259\n",
       " 0.0993433  0.0977044  0.100844      0.0997558  0.0987005  0.099664\n",
       " 0.0936222  0.0935635  0.0864547     0.0926201  0.0938842  0.0942821\n",
       " 0.0975791  0.0996181  0.0982734     0.0957861  0.0995257  0.100255\n",
       " 0.106614   0.106421   0.111656      0.107874   0.106617   0.104711"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_X[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0764"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_X, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main In[20]:1\n",
      "┌ Info: [10]: Test accuracy: 0.8656\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [11]: Test accuracy: 0.8564\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [12]: Test accuracy: 0.8532\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [13]: Test accuracy: 0.8598\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [14]: Test accuracy: 0.8634\n",
      "└ @ Main In[20]:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 0.001!\n",
      "└ @ Main In[20]:17\n",
      "┌ Info: [15]: Test accuracy: 0.8828\n",
      "└ @ Main In[20]:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to SVHN_conv.bson\n",
      "└ @ Main In[20]:10\n",
      "┌ Info: [16]: Test accuracy: 0.8834\n",
      "└ @ Main In[20]:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to SVHN_conv.bson\n",
      "└ @ Main In[20]:10\n",
      "┌ Info: [17]: Test accuracy: 0.8838\n",
      "└ @ Main In[20]:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to SVHN_conv.bson\n",
      "└ @ Main In[20]:10\n",
      "┌ Info: [18]: Test accuracy: 0.8836\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [19]: Test accuracy: 0.8818\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [20]: Test accuracy: 0.8810\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [21]: Test accuracy: 0.8804\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [22]: Test accuracy: 0.8784\n",
      "└ @ Main In[20]:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "└ @ Main In[20]:17\n",
      "┌ Info: [23]: Test accuracy: 0.8804\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [24]: Test accuracy: 0.8798\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [25]: Test accuracy: 0.8802\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [26]: Test accuracy: 0.8800\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [27]: Test accuracy: 0.8800\n",
      "└ @ Main In[20]:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "└ @ Main In[20]:17\n",
      "┌ Info: [28]: Test accuracy: 0.8796\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [29]: Test accuracy: 0.8798\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [30]: Test accuracy: 0.8794\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [31]: Test accuracy: 0.8794\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [32]: Test accuracy: 0.8794\n",
      "└ @ Main In[20]:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "└ @ Main In[20]:17\n",
      "┌ Info: [33]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [34]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [35]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [36]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [37]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "└ @ Main In[20]:17\n",
      "┌ Info: [38]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [39]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n",
      "┌ Info: [40]: Test accuracy: 0.8790\n",
      "└ @ Main In[20]:8\n"
     ]
    }
   ],
   "source": [
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0\n",
    "last_improvement = 0\n",
    "for epoch = 0:epochs\n",
    "    global best_acc, last_improvement\n",
    "    Flux.train!(loss, params(model), train_X, opt)\n",
    "    acc = accuracy(test_X, test_labels)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch, acc))\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to SVHN_conv.bson\")\n",
    "        BSON.@save \"SVHN_conv.bson\" model epoch acc\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if epoch - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\" -> Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if epoch - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
